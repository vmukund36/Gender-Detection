{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2307 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('C:\\\\Users\\\\vmuku\\\\OneDrive\\\\Desktop\\\\Gender detection\\Gender-Detection-master\\\\gender_dataset_face',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2307 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('C:\\\\Users\\\\vmuku\\\\OneDrive\\\\Desktop\\\\Gender detection\\Gender-Detection-master\\\\gender_dataset_face',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 13s 175ms/step - loss: 0.1119 - accuracy: 0.9567 - val_loss: 0.0593 - val_accuracy: 0.9809\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 13s 176ms/step - loss: 0.1008 - accuracy: 0.9619 - val_loss: 0.0592 - val_accuracy: 0.9805\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 12s 173ms/step - loss: 0.0982 - accuracy: 0.9593 - val_loss: 0.0623 - val_accuracy: 0.9788\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 10s 139ms/step - loss: 0.1070 - accuracy: 0.9567 - val_loss: 0.0595 - val_accuracy: 0.9779\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.1144 - accuracy: 0.9549 - val_loss: 0.0576 - val_accuracy: 0.9805\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 10s 145ms/step - loss: 0.1011 - accuracy: 0.9610 - val_loss: 0.0594 - val_accuracy: 0.9779\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.1148 - accuracy: 0.9562 - val_loss: 0.0702 - val_accuracy: 0.9740\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.1076 - accuracy: 0.9571 - val_loss: 0.0690 - val_accuracy: 0.9757\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 11s 147ms/step - loss: 0.0971 - accuracy: 0.9623 - val_loss: 0.0583 - val_accuracy: 0.9805\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 14s 190ms/step - loss: 0.0904 - accuracy: 0.9679 - val_loss: 0.0535 - val_accuracy: 0.9809\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 13s 178ms/step - loss: 0.0752 - accuracy: 0.9727 - val_loss: 0.0523 - val_accuracy: 0.9818\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 13s 181ms/step - loss: 0.0909 - accuracy: 0.9688 - val_loss: 0.0705 - val_accuracy: 0.9705\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 14s 197ms/step - loss: 0.0850 - accuracy: 0.9649 - val_loss: 0.0506 - val_accuracy: 0.9814\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 14s 198ms/step - loss: 0.0794 - accuracy: 0.9692 - val_loss: 0.0630 - val_accuracy: 0.9766\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 15s 209ms/step - loss: 0.1004 - accuracy: 0.9614 - val_loss: 0.0537 - val_accuracy: 0.9792\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 13s 181ms/step - loss: 0.0771 - accuracy: 0.9701 - val_loss: 0.0566 - val_accuracy: 0.9796\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 14s 198ms/step - loss: 0.0802 - accuracy: 0.9692 - val_loss: 0.0491 - val_accuracy: 0.9827\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 13s 182ms/step - loss: 0.0792 - accuracy: 0.9692 - val_loss: 0.0457 - val_accuracy: 0.9848\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 16s 215ms/step - loss: 0.0685 - accuracy: 0.9744 - val_loss: 0.0425 - val_accuracy: 0.9853\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 13s 181ms/step - loss: 0.0938 - accuracy: 0.9636 - val_loss: 0.0901 - val_accuracy: 0.9649\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 11s 158ms/step - loss: 0.0830 - accuracy: 0.9671 - val_loss: 0.0430 - val_accuracy: 0.9861\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 12s 163ms/step - loss: 0.0716 - accuracy: 0.9714 - val_loss: 0.0401 - val_accuracy: 0.9844\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 12s 161ms/step - loss: 0.0705 - accuracy: 0.9740 - val_loss: 0.0540 - val_accuracy: 0.9788\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 12s 171ms/step - loss: 0.0713 - accuracy: 0.9740 - val_loss: 0.0392 - val_accuracy: 0.9874\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 10s 141ms/step - loss: 0.0739 - accuracy: 0.9727 - val_loss: 0.0457 - val_accuracy: 0.9814\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0706 - accuracy: 0.9749 - val_loss: 0.0341 - val_accuracy: 0.9879\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.1055 - accuracy: 0.9601 - val_loss: 0.0362 - val_accuracy: 0.9883\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 11s 150ms/step - loss: 0.1005 - accuracy: 0.9614 - val_loss: 0.0518 - val_accuracy: 0.9818\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 11s 146ms/step - loss: 0.0878 - accuracy: 0.9662 - val_loss: 0.0511 - val_accuracy: 0.9801\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0653 - accuracy: 0.9740 - val_loss: 0.0447 - val_accuracy: 0.9827\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 10s 137ms/step - loss: 0.0833 - accuracy: 0.9688 - val_loss: 0.0433 - val_accuracy: 0.9857\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0670 - accuracy: 0.9779 - val_loss: 0.0355 - val_accuracy: 0.9874\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 10s 132ms/step - loss: 0.0628 - accuracy: 0.9757 - val_loss: 0.0366 - val_accuracy: 0.9866\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0810 - accuracy: 0.9653 - val_loss: 0.0458 - val_accuracy: 0.9857\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0659 - accuracy: 0.9740 - val_loss: 0.0343 - val_accuracy: 0.9874\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 10s 139ms/step - loss: 0.0530 - accuracy: 0.9818 - val_loss: 0.0302 - val_accuracy: 0.9892\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 10s 142ms/step - loss: 0.0706 - accuracy: 0.9775 - val_loss: 0.0367 - val_accuracy: 0.9883\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 10s 132ms/step - loss: 0.0666 - accuracy: 0.9740 - val_loss: 0.0275 - val_accuracy: 0.9913\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0585 - accuracy: 0.9770 - val_loss: 0.0309 - val_accuracy: 0.9896\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.0554 - accuracy: 0.9831 - val_loss: 0.0281 - val_accuracy: 0.9918\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0642 - accuracy: 0.9788 - val_loss: 0.0275 - val_accuracy: 0.9913\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0640 - accuracy: 0.9749 - val_loss: 0.0368 - val_accuracy: 0.9874\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 10s 132ms/step - loss: 0.0558 - accuracy: 0.9801 - val_loss: 0.0245 - val_accuracy: 0.9931\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0965 - accuracy: 0.9575 - val_loss: 0.0458 - val_accuracy: 0.9853\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0701 - accuracy: 0.9731 - val_loss: 0.0311 - val_accuracy: 0.9900\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 10s 132ms/step - loss: 0.0641 - accuracy: 0.9766 - val_loss: 0.0401 - val_accuracy: 0.9905\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0573 - accuracy: 0.9770 - val_loss: 0.0257 - val_accuracy: 0.9926\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.0508 - accuracy: 0.9831 - val_loss: 0.0234 - val_accuracy: 0.9952\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0515 - accuracy: 0.9822 - val_loss: 0.0277 - val_accuracy: 0.9913\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0504 - accuracy: 0.9844 - val_loss: 0.0254 - val_accuracy: 0.9905\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.0538 - accuracy: 0.9805 - val_loss: 0.0350 - val_accuracy: 0.9866\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0700 - accuracy: 0.9736 - val_loss: 0.0262 - val_accuracy: 0.9939\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.0494 - accuracy: 0.9814 - val_loss: 0.0224 - val_accuracy: 0.9939\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.0203 - val_accuracy: 0.9944\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0511 - accuracy: 0.9783 - val_loss: 0.0276 - val_accuracy: 0.9918\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 9s 130ms/step - loss: 0.0510 - accuracy: 0.9840 - val_loss: 0.0223 - val_accuracy: 0.9926\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0512 - accuracy: 0.9827 - val_loss: 0.0274 - val_accuracy: 0.9926\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0490 - accuracy: 0.9805 - val_loss: 0.0430 - val_accuracy: 0.9827\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0548 - accuracy: 0.9770 - val_loss: 0.0248 - val_accuracy: 0.9935\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 10s 137ms/step - loss: 0.0478 - accuracy: 0.9818 - val_loss: 0.0270 - val_accuracy: 0.9909\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.0493 - accuracy: 0.9818 - val_loss: 0.0187 - val_accuracy: 0.9935\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0630 - accuracy: 0.9753 - val_loss: 0.0298 - val_accuracy: 0.9892\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0462 - accuracy: 0.9827 - val_loss: 0.0185 - val_accuracy: 0.9952\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.0473 - accuracy: 0.9822 - val_loss: 0.0301 - val_accuracy: 0.9887\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0524 - accuracy: 0.9766 - val_loss: 0.0200 - val_accuracy: 0.9935\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.0406 - accuracy: 0.9848 - val_loss: 0.0144 - val_accuracy: 0.9965\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 10s 138ms/step - loss: 0.0578 - accuracy: 0.9757 - val_loss: 0.0252 - val_accuracy: 0.9918\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0847 - accuracy: 0.9679 - val_loss: 0.0642 - val_accuracy: 0.9805\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0711 - accuracy: 0.9718 - val_loss: 0.0260 - val_accuracy: 0.9913\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0546 - accuracy: 0.9749 - val_loss: 0.0249 - val_accuracy: 0.9926\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0224 - val_accuracy: 0.9931\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 0.0244 - val_accuracy: 0.9922\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0363 - accuracy: 0.9861 - val_loss: 0.0219 - val_accuracy: 0.9918\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 10s 132ms/step - loss: 0.0388 - accuracy: 0.9835 - val_loss: 0.0231 - val_accuracy: 0.9918\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0335 - accuracy: 0.9840 - val_loss: 0.0216 - val_accuracy: 0.9926\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0434 - accuracy: 0.9831 - val_loss: 0.0191 - val_accuracy: 0.9952\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 10s 141ms/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 0.0225 - val_accuracy: 0.9900\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 10s 138ms/step - loss: 0.0388 - accuracy: 0.9840 - val_loss: 0.0151 - val_accuracy: 0.9970\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 10s 132ms/step - loss: 0.0374 - accuracy: 0.9870 - val_loss: 0.0185 - val_accuracy: 0.9939\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0543 - accuracy: 0.9770 - val_loss: 0.0291 - val_accuracy: 0.9870\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0421 - accuracy: 0.9831 - val_loss: 0.0186 - val_accuracy: 0.9944\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0397 - accuracy: 0.9853 - val_loss: 0.0233 - val_accuracy: 0.9926\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0358 - accuracy: 0.9866 - val_loss: 0.0146 - val_accuracy: 0.9961\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 10s 138ms/step - loss: 0.0335 - accuracy: 0.9861 - val_loss: 0.0141 - val_accuracy: 0.9961\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 11s 152ms/step - loss: 0.0351 - accuracy: 0.9870 - val_loss: 0.0223 - val_accuracy: 0.9909\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 10s 135ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0189 - val_accuracy: 0.9944\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.0153 - val_accuracy: 0.9952\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 10s 137ms/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.0193 - val_accuracy: 0.9948\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0597 - accuracy: 0.9762 - val_loss: 0.0425 - val_accuracy: 0.9848\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 10s 133ms/step - loss: 0.0512 - accuracy: 0.9822 - val_loss: 0.0276 - val_accuracy: 0.9918\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 11s 146ms/step - loss: 0.0400 - accuracy: 0.9840 - val_loss: 0.0225 - val_accuracy: 0.9944\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 11s 149ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.0113 - val_accuracy: 0.9974\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0421 - accuracy: 0.9853 - val_loss: 0.0167 - val_accuracy: 0.9952\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 10s 137ms/step - loss: 0.0321 - accuracy: 0.9870 - val_loss: 0.0154 - val_accuracy: 0.9939\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 10s 134ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.0174 - val_accuracy: 0.9935\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 10s 137ms/step - loss: 0.0390 - accuracy: 0.9866 - val_loss: 0.0122 - val_accuracy: 0.9974\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 10s 137ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 0.0145 - val_accuracy: 0.9961\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 10s 140ms/step - loss: 0.0311 - accuracy: 0.9879 - val_loss: 0.0106 - val_accuracy: 0.9970\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 10s 136ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 10s 141ms/step - loss: 0.0378 - accuracy: 0.9879 - val_loss: 0.0188 - val_accuracy: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd808b6730>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\vmuku\\\\OneDrive\\\\Desktop\\\\Gender detection\\\\Gender-Detection-master\\\\gender_dataset_face\\\\man'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(path):\n\u001b[0;32m      8\u001b[0m         img \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mvmuku\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mGender detection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGender-Detection-master\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mgender_dataset_face\u001b[39m\u001b[38;5;124m'\u001b[39m, img)\n\u001b[1;32m----> 9\u001b[0m         test_image \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         test_image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(test_image)\n\u001b[0;32m     11\u001b[0m         test_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(test_image, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\vmuku\\\\OneDrive\\\\Desktop\\\\Gender detection\\\\Gender-Detection-master\\\\gender_dataset_face\\\\man'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "image=[]\n",
    "path= 'C:\\\\Users\\\\vmuku\\\\OneDrive\\\\Desktop\\\\Gender detection\\Gender-Detection-master\\\\gender_dataset_face'\n",
    "lenpath = len(path)\n",
    "for img in os.listdir(path):\n",
    "        img = os.path.join('C:\\\\Users\\\\vmuku\\\\OneDrive\\\\Desktop\\\\Gender detection\\Gender-Detection-master\\\\gender_dataset_face', img)\n",
    "        test_image = tf.keras.preprocessing.image.load_img(img, target_size = (64, 64))\n",
    "        test_image = tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        image.append(test_image)\n",
    "        result = cnn.predict(image)\n",
    "        training_set.class_indices\n",
    "        if result[0][0] == 0:\n",
    "           prediction = 'woman'\n",
    "        else:\n",
    "           prediction = 'man'\n",
    "        print(result)\n",
    "        print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [73, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, accuracy_score\n\u001b[1;32m----> 2\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n\u001b[0;32m      4\u001b[0m accuracy_score(test_set, result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[0;32m    223\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    224\u001b[0m ):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [73, 1]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(test_set, result)\n",
    "print(cm)\n",
    "accuracy_score(test_set, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "man\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = tf.keras.preprocessing.image.load_img('C:\\\\Users\\\\vmuku\\\\OneDrive\\\\Desktop\\\\pictures\\\\picture4.jpeg', target_size = (64, 64))\n",
    "test_image = tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'woman'\n",
    "else:\n",
    "  prediction = 'man'\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
